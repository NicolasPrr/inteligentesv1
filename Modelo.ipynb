{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hadware</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Liberias </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation, Add\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n",
    "import PIL\n",
    "\n",
    "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Definimos las constantes, hiperparametros, etc</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.image_data_format() CHANNELS_LAST\n",
    "nb_train_samples = 7947 \n",
    "nb_validation_samples = 300\n",
    "\n",
    "\n",
    "train_dir = 'data/train'\n",
    "dev_dir = 'data/dev'\n",
    "test_dir = ' data/test'\n",
    "epochs = 5\n",
    "width, height = 306, 306\n",
    "batch_size = 20\n",
    "steps = nb_train_samples // batch_size\n",
    "validation_steps = nb_validation_samples // batch_size\n",
    "#Tamaño profundidad de filtros\n",
    "filtersConv1 = 32\n",
    "filtersConv2 = 32\n",
    "filtersConv3 = 64\n",
    "\n",
    "#Tamaño de los filtros\n",
    "filter_size1 = (3,3)\n",
    "filter_size2 = (3,3)\n",
    "filter_size3 = (3,3)\n",
    "#PoolSizes\n",
    "pool_size1 = (2,2)\n",
    "pool_size2 = (2,2)\n",
    "pool_size3 = (2,2)\n",
    "\n",
    "number_class = 3\n",
    "learning_rate = 0.005\n",
    "lr = learning_rate\n",
    "#Limpiamos sesiones previas\n",
    "K.clear_session()\n",
    "\n",
    "filter_convs = [filtersConv1, filtersConv2, filtersConv3]\n",
    "filter_sizes = [filter_size1, filter_size2, filter_size3]\n",
    "pool_sizes   = [pool_size1, pool_size2, pool_size3]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7953 images belonging to 3 classes.\n",
      "Found 311 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.2,0.8],\n",
    "    rotation_range=20,\n",
    ")\n",
    "    \n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(width, height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "    \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    dev_dir,\n",
    "    target_size=(width, height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Modelo</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape, filter_convs, filter_sizes, pool_sizes):\n",
    "    width, height = input_shape[0], input_shape[1] \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, width, height)\n",
    "    else:\n",
    "        input_shape = (width, height, 3)\n",
    "\n",
    "    network =Sequential()\n",
    "    print(input_shape)\n",
    "    #first layer\n",
    "    network.add(Convolution2D( filter_convs[0],\n",
    "                               filter_sizes[0], \n",
    "                               padding='same', \n",
    "                               input_shape = input_shape,\n",
    "                               activation='relu'\n",
    "                             ))\n",
    "    network.add(MaxPooling2D(pool_size=pool_sizes[0]))\n",
    "    \n",
    "    #Second layer\n",
    "    network.add(Convolution2D( filter_convs[1],\n",
    "                               filter_sizes[1],  \n",
    "                               activation='relu'\n",
    "                             ))\n",
    "    network.add(MaxPooling2D(pool_size=pool_sizes[1]))\n",
    "    \n",
    "    #third layer\n",
    "    network.add(Convolution2D( filter_convs[2],\n",
    "                               filter_sizes[2], \n",
    "                               activation='relu'\n",
    "                             ))\n",
    "    \n",
    "    network.add(MaxPooling2D(pool_size=pool_sizes[2]))\n",
    "    \n",
    "    \n",
    "    network.add(Flatten())\n",
    "    network.add(Dense(64))\n",
    "    network.add(Activation('relu'))\n",
    "    network.add(Dropout(0.5))\n",
    "    network.add(Dense(3))\n",
    "    network.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (width, height)\n",
    "cnn = model(input_shape, filter_convs, filter_sizes, pool_sizes )\n",
    "#Primer modelo\n",
    "#cnn.compile(loss='mean_squared_error', optimizer='Adam', metrics = ['accuracy'])\n",
    "#CategoricalCrossentropy\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer='Adam', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Entrenamiento del modelo</h2>\n",
    "\n",
    "Una vez entrenado se guarda el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        use_multiprocessing=True,\n",
    "        workers = 4\n",
    "    )\n",
    "#Una vez que se entrena, el modelo se guardara en el directorio especificado\n",
    "dir = 'modelo2/'+ str(datetime.datetime.now()) + '/'\n",
    "if os.path.exists(dir) == False:\n",
    "    os.mkdir(dir)\n",
    "#os.path.exists(dir)\n",
    "cnn.save(dir + 'modelo.h5')\n",
    "cnn.save_weights(dir  +'weights.h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'modelo2/'+ str(datetime.datetime.now()) + '/'\n",
    "if os.path.exists(dir) == False:\n",
    "    os.mkdir(dir)\n",
    "#os.path.exists(dir)\n",
    "cnn.save(dir + 'modelo.h5')\n",
    "cnn.save_weights(dir  +'weights.h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cargamos el modelo pre entrenado</h2> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model= tf.keras.models.load_model('modelo/2020-02-07 00:27:13.124754/modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        use_multiprocessing=True,\n",
    "        workers = 4\n",
    ")\n",
    "dir = 'modelo2/'+ str(datetime.datetime.now()) + '/'\n",
    "if os.path.exists(dir) == False:\n",
    "    os.mkdir(dir)\n",
    "#os.path.exists(dir)\n",
    "loaded_model.save(dir + 'modelo.h5')\n",
    "loaded_model.save_weights(dir  +'weights.h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('test.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as img\n",
    "images_set = []\n",
    "for index, row in results.iterrows():\n",
    "   # print(row['Id'])\n",
    "    data = img.open('Selfie-dataset/images/' + str(row['Id']) + '.jpg')\n",
    "    images_set.append(np.asarray(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = loaded_model.predict(np.array(images_set))\n",
    "np.argmax(rst, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeIndex(results):\n",
    "    rta = []\n",
    "    for i in range(len(results)):\n",
    "        #print(results[i])\n",
    "        if(results[i] == 0):\n",
    "            rta.append(2)\n",
    "        elif results[i] == 1:\n",
    "            rta.append(0)\n",
    "        else:\n",
    "            rta.append(1)\n",
    "    return rta\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rta = changeIndex(np.argmax(rst, axis = 1))\n",
    "results['Category'] =  rta\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.hist(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen('PATH_TO_DATASET_DIR/Dataset',\n",
    "                              # only read images from `test` directory\n",
    "                              #classes=['test'],\n",
    "                              # don't generate labels\n",
    "                              #class_mode=None,\n",
    "                              # don't shuffle\n",
    "                              shuffle=False,\n",
    "                              # use same size as in training\n",
    "                              target_size=(306, 306))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 306, 306, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 153, 153, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 151, 151, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 73, 73, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                5308480   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 5,337,315\n",
      "Trainable params: 5,337,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model= tf.keras.models.load_model('modelo2/2020-02-07 13:48:29.638705/modelo.h5')\n",
    "loaded_model.summary()\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-487b60bb4bfb>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 397 steps, validate for 15 steps\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "396/397 [============================>.] - ETA: 0s - loss: 0.5476 - accuracy: 0.7596WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "397/397 [==============================] - 190s 480ms/step - loss: 0.5472 - accuracy: 0.7597 - val_loss: 0.5010 - val_accuracy: 0.7633\n",
      "Epoch 2/5\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "396/397 [============================>.] - ETA: 0s - loss: 0.5374 - accuracy: 0.7628WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "397/397 [==============================] - 170s 428ms/step - loss: 0.5374 - accuracy: 0.7626 - val_loss: 0.4608 - val_accuracy: 0.7600\n",
      "Epoch 3/5\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "396/397 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.7653WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "397/397 [==============================] - 171s 432ms/step - loss: 0.5376 - accuracy: 0.7653 - val_loss: 0.6038 - val_accuracy: 0.7200\n",
      "Epoch 4/5\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "396/397 [============================>.] - ETA: 0s - loss: 0.5279 - accuracy: 0.7671WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "397/397 [==============================] - 169s 427ms/step - loss: 0.5276 - accuracy: 0.7674 - val_loss: 0.4928 - val_accuracy: 0.7900\n",
      "Epoch 5/5\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "396/397 [============================>.] - ETA: 0s - loss: 0.5308 - accuracy: 0.7647WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "397/397 [==============================] - 172s 433ms/step - loss: 0.5310 - accuracy: 0.7644 - val_loss: 0.4796 - val_accuracy: 0.7700\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics = ['accuracy'])\n",
    "try:\n",
    "    loaded_model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples // batch_size,\n",
    "            use_multiprocessing=True,\n",
    "            workers = 4\n",
    "        )\n",
    "except tf.errors.ResourceExhaustedError as e:\n",
    "    #Una vez que se entrena, el modelo se guardara en el directorio especificado\n",
    "    dir = 'modelo2/'+ str(datetime.datetime.now()) + '/'\n",
    "    if os.path.exists(dir) == False:\n",
    "        os.mkdir(dir)\n",
    "    #os.path.exists(dir)\n",
    "    loaded_model.save(dir + 'modelo.h5')\n",
    "    loaded_model.save_weights(dir  +'weights.h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'modelo2/'+ str(datetime.datetime.now()) + '/'\n",
    "if os.path.exists(dir) == False:\n",
    "    os.mkdir(dir)\n",
    "    #os.path.exists(dir)\n",
    "loaded_model.save(dir + 'modelo.h5')\n",
    "loaded_model.save_weights(dir  +'weights.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
